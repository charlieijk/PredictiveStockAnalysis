{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Main Pipeline for Stock Price Prediction Project\n",
        "Orchestrates data collection, feature engineering, model training, and evaluation\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import custom modules\n",
        "from stocks import StockDataCollector\n",
        "from feature_engineering import FeatureEngineer\n",
        "from models import StockPredictionModels\n",
        "from visualization import StockVisualizer\n",
        "import config\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=config.LOGGING_CONFIG['level'],\n",
        "    format=config.LOGGING_CONFIG['format'],\n",
        "    handlers=[\n",
        "        logging.FileHandler(config.LOGGING_CONFIG['log_file']),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class StockPredictionPipeline:\n",
        "    \"\"\"Main pipeline for stock prediction workflow\"\"\"\n",
        "    \n",
        "    def __init__(self, symbol: str, start_date: str = None, end_date: str = None):\n",
        "        \"\"\"\n",
        "        Initialize pipeline\n",
        "        \n",
        "        Args:\n",
        "            symbol: Stock symbol\n",
        "            start_date: Start date for data collection\n",
        "            end_date: End date for data collection\n",
        "        \"\"\"\n",
        "        self.symbol = symbol\n",
        "        self.start_date = start_date or config.DATA_CONFIG['start_date']\n",
        "        self.end_date = end_date or config.DATA_CONFIG['end_date']\n",
        "        \n",
        "        # Initialize components\n",
        "        self.collector = StockDataCollector(symbol, start_date, end_date)\n",
        "        self.engineer = FeatureEngineer(scaling_method=config.FEATURE_CONFIG['scaling_method'])\n",
        "        self.trainer = StockPredictionModels(config.MODEL_CONFIG)\n",
        "        self.visualizer = StockVisualizer()\n",
        "        \n",
        "        # Storage for results\n",
        "        self.raw_data = None\n",
        "        self.engineered_data = None\n",
        "        self.predictions = {}\n",
        "        self.performance = {}\n",
        "        \n",
        "    def run_pipeline(self):\n",
        "        \"\"\"Run the complete pipeline\"\"\"\n",
        "        logger.info(f\"Starting pipeline for {self.symbol}\")\n",
        "        logger.info(\"=\" * 50)\n",
        "        \n",
        "        # Step 1: Data Collection\n",
        "        self.collect_data()\n",
        "        \n",
        "        # Step 2: Feature Engineering\n",
        "        self.engineer_features()\n",
        "        \n",
        "        # Step 3: Model Training\n",
        "        self.train_models()\n",
        "        \n",
        "        # Step 4: Evaluation\n",
        "        self.evaluate_models()\n",
        "        \n",
        "        # Step 5: Visualization\n",
        "        self.create_visualizations()\n",
        "        \n",
        "        # Step 6: Save Results\n",
        "        self.save_results()\n",
        "        \n",
        "        logger.info(\"=\" * 50)\n",
        "        logger.info(\"Pipeline completed successfully!\")\n",
        "        \n",
        "        return self.performance\n",
        "    \n",
        "    def collect_data(self):\n",
        "        \"\"\"Collect and prepare stock data\"\"\"\n",
        "        logger.info(\"Step 1: Collecting stock data...\")\n",
        "        \n",
        "        try:\n",
        "            # Fetch raw data\n",
        "            self.raw_data = self.collector.fetch_stock_data()\n",
        "            logger.info(f\"Collected {len(self.raw_data)} days of data\")\n",
        "            \n",
        "            # Calculate technical indicators\n",
        "            self.collector.calculate_moving_averages()\n",
        "            self.collector.calculate_rsi()\n",
        "            self.collector.calculate_macd()\n",
        "            self.collector.calculate_bollinger_bands()\n",
        "            self.collector.calculate_volatility()\n",
        "            self.collector.calculate_volume_indicators()\n",
        "            self.collector.add_price_features()\n",
        "            \n",
        "            self.raw_data = self.collector.data\n",
        "            \n",
        "            # Save raw data\n",
        "            data_path = os.path.join(config.DATA_DIR, \n",
        "                                     f\"{self.symbol}_raw_data_{datetime.now().strftime('%Y%m%d')}.csv\")\n",
        "            self.raw_data.to_csv(data_path, index=False)\n",
        "            logger.info(f\"Raw data saved to {data_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in data collection: {str(e)}\")\n",
        "            raise\n",
        "    \n",
        "    def engineer_features(self):\n",
        "        \"\"\"Engineer features for model training\"\"\"\n",
        "        logger.info(\"Step 2: Engineering features...\")\n",
        "        \n",
        "        try:\n",
        "            # Create advanced features\n",
        "            self.engineered_data = self.engineer.engineer_all_features(\n",
        "                self.raw_data,\n",
        "                target_col='Close',\n",
        "                sequence_length=config.DATA_CONFIG['sequence_length']\n",
        "            )\n",
        "            \n",
        "            logger.info(f\"Created {len(self.engineered_data['feature_names'])} features\")\n",
        "            logger.info(f\"Selected top {len(self.engineered_data['selected_features'])} features\")\n",
        "            \n",
        "            # Save feature names\n",
        "            features_path = os.path.join(config.DATA_DIR, \n",
        "                                        f\"{self.symbol}_features_{datetime.now().strftime('%Y%m%d')}.json\")\n",
        "            with open(features_path, 'w') as f:\n",
        "                json.dump({\n",
        "                    'all_features': self.engineered_data['feature_names'],\n",
        "                    'selected_features': self.engineered_data['selected_features']\n",
        "                }, f, indent=4)\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature engineering: {str(e)}\")\n",
        "            raise\n",
        "    \n",
        "    def train_models(self):\n",
        "        \"\"\"Train all models\"\"\"\n",
        "        logger.info(\"Step 3: Training models...\")\n",
        "        \n",
        "        # Prepare data splits\n",
        "        features = self.engineered_data['features']\n",
        "        target = self.engineered_data['target']\n",
        "        features_lstm = self.engineered_data['features_lstm']\n",
        "        target_lstm = self.engineered_data['target_lstm']\n",
        "        \n",
        "        # Calculate split indices\n",
        "        train_size = int(len(features) * (1 - config.DATA_CONFIG['test_size']))\n",
        "        val_size = int(train_size * config.DATA_CONFIG['validation_size'])\n",
        "        \n",
        "        # Traditional ML data split\n",
        "        X_train = features[:train_size-val_size].values\n",
        "        y_train = target[:train_size-val_size].values\n",
        "        X_val = features[train_size-val_size:train_size].values\n",
        "        y_val = target[train_size-val_size:train_size].values\n",
        "        X_test = features[train_size:].values\n",
        "        y_test = target[train_size:].values\n",
        "        \n",
        "        # LSTM data split\n",
        "        lstm_train_size = int(len(features_lstm) * (1 - config.DATA_CONFIG['test_size']))\n",
        "        lstm_val_size = int(lstm_train_size * config.DATA_CONFIG['validation_size'])\n",
        "        \n",
        "        X_train_lstm = features_lstm[:lstm_train_size-lstm_val_size]\n",
        "        y_train_lstm = target_lstm[:lstm_train_size-lstm_val_size]\n",
        "        X_val_lstm = features_lstm[lstm_train_size-lstm_val_size:lstm_train_size]\n",
        "        y_val_lstm = target_lstm[lstm_train_size-lstm_val_size:lstm_train_size]\n",
        "        X_test_lstm = features_lstm[lstm_train_size:]\n",
        "        y_test_lstm = target_lstm[lstm_train_size:]\n",
        "        \n",
        "        # Store test data for later evaluation\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.X_test_lstm = X_test_lstm\n",
        "        self.y_test_lstm = y_test_lstm\n",
        "        \n",
        "        # Train models\n",
        "        models_to_train = [\n",
        "            ('Linear Regression', 'linear'),\n",
        "            ('Random Forest', 'random_forest'),\n",
        "            ('Gradient Boosting', 'gradient_boosting')\n",
        "        ]\n",
        "        \n",
        "        for model_name, model_type in models_to_train:\n",
        "            try:\n",
        "                logger.info(f\"Training {model_name}...\")\n",
        "                \n",
        "                if model_type == 'linear':\n",
        "                    self.trainer.train_linear_regression(X_train, y_train, X_val, y_val)\n",
        "                elif model_type == 'random_forest':\n",
        "                    self.trainer.train_random_forest(X_train, y_train, X_val, y_val)\n",
        "                elif model_type == 'gradient_boosting':\n",
        "                    self.trainer.train_gradient_boosting(X_train, y_train, X_val, y_val)\n",
        "                \n",
        "                logger.info(f\"{model_name} training completed\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error training {model_name}: {str(e)}\")\n",
        "        \n",
        "        # Train LSTM if enabled\n",
        "        if config.TRAINING_CONFIG.get('train_lstm', True):\n",
        "            try:\n",
        "                logger.info(\"Training LSTM model...\")\n",
        "                self.trainer.train_lstm(X_train_lstm, y_train_lstm, \n",
        "                                       X_val_lstm, y_val_lstm)\n",
        "                logger.info(\"LSTM training completed\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error training LSTM: {str(e)}\")\n",
        "        \n",
        "        # Train ensemble\n",
        "        try:\n",
        "            logger.info(\"Training Ensemble model...\")\n",
        "            self.trainer.train_ensemble(X_train, y_train, X_val, y_val)\n",
        "            logger.info(\"Ensemble training completed\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error training Ensemble: {str(e)}\")\n",
        "    \n",
        "    def evaluate_models(self):\n",
        "        \"\"\"Evaluate all trained models\"\"\"\n",
        "        logger.info(\"Step 4: Evaluating models...\")\n",
        "        \n",
        "        # Make predictions\n",
        "        for model_name in self.trainer.models.keys():\n",
        "            try:\n",
        "                if 'lstm' in model_name.lower() or 'gru' in model_name.lower():\n",
        "                    self.predictions[model_name] = self.trainer.predict(\n",
        "                        model_name, self.X_test_lstm\n",
        "                    )\n",
        "                else:\n",
        "                    self.predictions[model_name] = self.trainer.predict(\n",
        "                        model_name, self.X_test\n",
        "                    )\n",
        "                \n",
        "                logger.info(f\"Generated predictions for {model_name}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error predicting with {model_name}: {str(e)}\")\n",
        "        \n",
        "        # Calculate performance metrics for each model\n",
        "        comparison_data = []\n",
        "        for model_name, predictions in self.predictions.items():\n",
        "            if 'lstm' in model_name.lower():\n",
        "                metrics = self.trainer.calculate_metrics(self.y_test_lstm, predictions)\n",
        "            else:\n",
        "                metrics = self.trainer.calculate_metrics(self.y_test, predictions)\n",
        "\n",
        "            comparison_data.append({\n",
        "                'Model': model_name,\n",
        "                'RMSE': metrics['rmse'],\n",
        "                'MAE': metrics['mae'],\n",
        "                'R2': metrics['r2'],\n",
        "                'Directional_Accuracy': metrics['directional_accuracy']\n",
        "            })\n",
        "\n",
        "        self.performance = pd.DataFrame(comparison_data).sort_values('RMSE')\n",
        "\n",
        "        \n",
        "        logger.info(\"\\nModel Performance Summary:\")\n",
        "        logger.info(\"-\" * 50)\n",
        "        print(self.performance.to_string())\n",
        "        \n",
        "        # Identify best model\n",
        "        best_model = self.performance.iloc[0]['Model']\n",
        "        logger.info(f\"\\nBest performing model: {best_model}\")\n",
        "        \n",
        "        # Save model comparison\n",
        "        comparison_path = os.path.join(config.OUTPUT_DIR,\n",
        "                                      f\"{self.symbol}_model_comparison_{datetime.now().strftime('%Y%m%d')}.csv\")\n",
        "        self.performance.to_csv(comparison_path, index=False)\n",
        "        \n",
        "    def create_visualizations(self):\n",
        "        \"\"\"Create and save visualizations\"\"\"\n",
        "        logger.info(\"Step 5: Creating visualizations...\")\n",
        "        \n",
        "        try:\n",
        "            # Prepare data for visualization\n",
        "            viz_data = {\n",
        "                'stock_data': self.raw_data,\n",
        "                'symbol': self.symbol,\n",
        "                'indicators': ['SMA_20', 'SMA_50', 'SMA_200'],\n",
        "                'predictions': self.predictions,\n",
        "                'actual': self.y_test if len(self.predictions) > 0 else None,\n",
        "                'comparison': self.performance,\n",
        "                'training_history': self.trainer.models.get('lstm_history', {})\n",
        "            }\n",
        "            \n",
        "            # Create visualizations\n",
        "            # Stock price plot\n",
        "            stock_fig = self.visualizer.plot_stock_price(\n",
        "                self.raw_data,\n",
        "                self.symbol,\n",
        "                ['SMA_20', 'SMA_50', 'SMA_200']\n",
        "            )\n",
        "\n",
        "            # Predictions plot\n",
        "            if self.predictions:\n",
        "                predictions_fig = self.visualizer.plot_predictions(\n",
        "                    self.y_test,\n",
        "                    self.predictions\n",
        "                )\n",
        "\n",
        "            # Model comparison\n",
        "            if not self.performance.empty:\n",
        "                comparison_fig = self.visualizer.plot_model_comparison(self.performance)\n",
        "            \n",
        "            logger.info(f\"Visualizations saved to {config.OUTPUT_DIR}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating visualizations: {str(e)}\")\n",
        "    \n",
        "    def save_results(self):\n",
        "        \"\"\"Save all results and models\"\"\"\n",
        "        logger.info(\"Step 6: Saving results...\")\n",
        "        \n",
        "        # Save models\n",
        "        for model_name in self.trainer.models.keys():\n",
        "            try:\n",
        "                model_path = os.path.join(config.MODEL_DIR,\n",
        "                                         f\"{self.symbol}_{model_name}_{datetime.now().strftime('%Y%m%d')}\")\n",
        "                self.trainer.save_model(model_name, model_path)\n",
        "                logger.info(f\"Saved {model_name} model\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error saving {model_name}: {str(e)}\")\n",
        "        \n",
        "        # Save predictions\n",
        "        if self.predictions:\n",
        "            predictions_df = pd.DataFrame(self.predictions)\n",
        "            predictions_df['actual'] = self.y_test[:len(predictions_df)]\n",
        "            predictions_path = os.path.join(config.OUTPUT_DIR,\n",
        "                                           f\"{self.symbol}_predictions_{datetime.now().strftime('%Y%m%d')}.csv\")\n",
        "            predictions_df.to_csv(predictions_path, index=False)\n",
        "            logger.info(f\"Predictions saved to {predictions_path}\")\n",
        "        \n",
        "        # Save summary report\n",
        "        self.generate_report()\n",
        "    \n",
        "    def generate_report(self):\n",
        "        \"\"\"Generate summary report\"\"\"\n",
        "        report_path = os.path.join(config.OUTPUT_DIR,\n",
        "                                  f\"{self.symbol}_report_{datetime.now().strftime('%Y%m%d')}.txt\")\n",
        "        \n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(f\"Stock Price Prediction Report\\n\")\n",
        "            f.write(f\"{'=' * 50}\\n\\n\")\n",
        "            f.write(f\"Symbol: {self.symbol}\\n\")\n",
        "            f.write(f\"Date Range: {self.start_date} to {self.end_date}\\n\")\n",
        "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "            \n",
        "            f.write(f\"Data Statistics:\\n\")\n",
        "            f.write(f\"- Total days: {len(self.raw_data)}\\n\")\n",
        "            f.write(f\"- Features created: {len(self.engineered_data['feature_names'])}\\n\")\n",
        "            f.write(f\"- Features selected: {len(self.engineered_data['selected_features'])}\\n\\n\")\n",
        "            \n",
        "            f.write(f\"Model Performance:\\n\")\n",
        "            f.write(self.performance.to_string())\n",
        "            f.write(f\"\\n\\nBest Model: {self.performance.iloc[0]['Model']}\\n\")\n",
        "            \n",
        "            f.write(f\"\\nTop 10 Selected Features:\\n\")\n",
        "            for i, feature in enumerate(self.engineered_data['selected_features'][:10]):\n",
        "                f.write(f\"  {i+1}. {feature}\\n\")\n",
        "\n",
        "        logger.info(f\"Report saved to {report_path}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the pipeline\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='Stock Price Prediction Pipeline')\n",
        "\n",
        "    parser.add_argument('symbol', type=str, help='Stock symbol (e.g., AAPL, GOOGL)')\n",
        "    parser.add_argument('--start-date', type=str, help='Start date (YYYY-MM-DD)')\n",
        "    parser.add_argument('--end-date', type=str, help='End date (YYYY-MM-DD)')\n",
        "    parser.add_argument('--dashboard', action='store_true', help='Launch dashboard after training')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = StockPredictionPipeline(\n",
        "        symbol=args.symbol,\n",
        "        start_date=args.start_date,\n",
        "        end_date=args.end_date\n",
        "    )\n",
        "\n",
        "    # Run pipeline\n",
        "    try:\n",
        "        results = pipeline.run_pipeline()\n",
        "\n",
        "        # Launch dashboard if requested\n",
        "        if args.dashboard:\n",
        "            logger.info(\"Launching dashboard...\")\n",
        "            from dashboard import app\n",
        "            app.run(\n",
        "                debug=config.DASHBOARD_CONFIG['debug'],\n",
        "                host=config.DASHBOARD_CONFIG['host'],\n",
        "                port=config.DASHBOARD_CONFIG['port']\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}