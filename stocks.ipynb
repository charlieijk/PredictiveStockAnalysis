{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfac727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stocks.py\n",
    "\n",
    "\"\"\"Utilities for downloading stock data and creating technical indicators.\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StockDataCollector:\n",
    "    \"\"\"Download OHLCV data and enrich it with technical indicators.\"\"\"\n",
    "\n",
    "    symbol: str\n",
    "    start_date: str = \"2020-01-01\"\n",
    "    end_date: Optional[str] = None\n",
    "    interval: str = \"1d\"\n",
    "    data: Optional[pd.DataFrame] = field(default=None, init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.symbol = self.symbol.upper()\n",
    "        if self.end_date is None:\n",
    "            self.end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Data fetching helpers\n",
    "    # ------------------------------------------------------------------\n",
    "    def fetch_stock_data(self, force: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Download historical OHLCV data from Yahoo Finance.\"\"\"\n",
    "        if self.data is not None and not force:\n",
    "            return self.data.copy()\n",
    "\n",
    "        logger.info(\n",
    "            \"Fetching data for %s from %s to %s (interval=%s)\",\n",
    "            self.symbol,\n",
    "            self.start_date,\n",
    "            self.end_date,\n",
    "            self.interval,\n",
    "        )\n",
    "\n",
    "        df = yf.download(\n",
    "            self.symbol,\n",
    "            start=self.start_date,\n",
    "            end=self.end_date,\n",
    "            interval=self.interval,\n",
    "            auto_adjust=True,\n",
    "            progress=False,\n",
    "        )\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(\n",
    "                f\"No data returned for {self.symbol} between {self.start_date} and {self.end_date}\"\n",
    "            )\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns=str.title, inplace=True)\n",
    "        df[\"Returns\"] = df[\"Close\"].pct_change()\n",
    "        df[\"Log_Returns\"] = np.log1p(df[\"Returns\"].fillna(0.0))\n",
    "\n",
    "        self.data = df\n",
    "        logger.info(\"Successfully fetched %d rows\", len(df))\n",
    "        return self.data.copy()\n",
    "\n",
    "    def fetch_raw_data(self, force: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Backward compatible alias used by existing notebooks.\"\"\"\n",
    "        return self.fetch_stock_data(force=force)\n",
    "\n",
    "    def _require_data(self) -> pd.DataFrame:\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data loaded. Call fetch_stock_data() first.\")\n",
    "        return self.data\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Indicator calculations\n",
    "    # ------------------------------------------------------------------\n",
    "    def calculate_moving_averages(self, windows: Optional[List[int]] = None) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        windows = windows or [10, 20, 50, 200]\n",
    "        for window in windows:\n",
    "            data[f\"SMA_{window}\"] = data[\"Close\"].rolling(window=window).mean()\n",
    "            data[f\"EMA_{window}\"] = data[\"Close\"].ewm(span=window, adjust=False).mean()\n",
    "        logger.info(\"Calculated moving averages for windows: %s\", windows)\n",
    "        return data\n",
    "\n",
    "    def calculate_rsi(self, period: int = 14) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        delta = data[\"Close\"].diff()\n",
    "        gain = np.where(delta > 0, delta, 0.0)\n",
    "        loss = np.where(delta < 0, -delta, 0.0)\n",
    "        avg_gain = pd.Series(gain, index=data.index).rolling(period).mean()\n",
    "        avg_loss = pd.Series(loss, index=data.index).rolling(period).mean()\n",
    "        rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "        data[f\"RSI_{period}\"] = 100 - (100 / (1 + rs))\n",
    "        logger.info(\"Calculated RSI_%d\", period)\n",
    "        return data\n",
    "\n",
    "    def calculate_macd(\n",
    "        self, fast: int = 12, slow: int = 26, signal: int = 9\n",
    "    ) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        ema_fast = data[\"Close\"].ewm(span=fast, adjust=False).mean()\n",
    "        ema_slow = data[\"Close\"].ewm(span=slow, adjust=False).mean()\n",
    "        data[\"MACD\"] = ema_fast - ema_slow\n",
    "        data[\"MACD_Signal\"] = data[\"MACD\"].ewm(span=signal, adjust=False).mean()\n",
    "        data[\"MACD_Histogram\"] = data[\"MACD\"] - data[\"MACD_Signal\"]\n",
    "        logger.info(\"Calculated MACD (%d, %d, %d)\", fast, slow, signal)\n",
    "        return data\n",
    "\n",
    "    def calculate_bollinger_bands(self, window: int = 20, num_std: float = 2.0) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        rolling = data[\"Close\"].rolling(window=window)\n",
    "        mean = rolling.mean()\n",
    "        std = rolling.std()\n",
    "        data[\"BB_Middle\"] = mean\n",
    "        data[\"BB_Upper\"] = mean + num_std * std\n",
    "        data[\"BB_Lower\"] = mean - num_std * std\n",
    "        data[\"BB_Width\"] = (data[\"BB_Upper\"] - data[\"BB_Lower\"]) / data[\"BB_Middle\"]\n",
    "        data[\"BB_Position\"] = (data[\"Close\"] - data[\"BB_Lower\"]) / (\n",
    "            data[\"BB_Upper\"] - data[\"BB_Lower\"]\n",
    "        )\n",
    "        logger.info(\"Calculated Bollinger Bands (window=%d, std=%.1f)\", window, num_std)\n",
    "        return data\n",
    "\n",
    "    def calculate_volatility(self, window: int = 20) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        data[\"Returns\"] = data[\"Returns\"].fillna(0.0)\n",
    "        data[f\"Volatility_{window}\"] = data[\"Returns\"].rolling(window).std() * np.sqrt(252)\n",
    "        data[\"ATR\"] = (\n",
    "            (data[\"High\"] - data[\"Low\"]).rolling(window).mean()\n",
    "        )\n",
    "        logger.info(\"Calculated volatility metrics (window=%d)\", window)\n",
    "        return data\n",
    "\n",
    "    def calculate_volume_indicators(self, window: int = 20) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        data[f\"Volume_MA_{window}\"] = data[\"Volume\"].rolling(window).mean()\n",
    "        obv = [0]\n",
    "        for i in range(1, len(data)):\n",
    "            if data[\"Close\"].iloc[i] > data[\"Close\"].iloc[i - 1]:\n",
    "                obv.append(obv[-1] + data[\"Volume\"].iloc[i])\n",
    "            elif data[\"Close\"].iloc[i] < data[\"Close\"].iloc[i - 1]:\n",
    "                obv.append(obv[-1] - data[\"Volume\"].iloc[i])\n",
    "            else:\n",
    "                obv.append(obv[-1])\n",
    "        data[\"OBV\"] = obv\n",
    "        data[\"Volume_ROC\"] = data[\"Volume\"].pct_change(periods=10) * 100\n",
    "        logger.info(\"Calculated volume indicators\")\n",
    "        return data\n",
    "\n",
    "    def add_price_features(self, lags: Optional[List[int]] = None) -> pd.DataFrame:\n",
    "        data = self._require_data()\n",
    "        lags = lags or [1, 3, 5, 10]\n",
    "        data[\"Price_Change\"] = data[\"Close\"] - data[\"Open\"]\n",
    "        data[\"High_Low_Ratio\"] = data[\"High\"] / data[\"Low\"]\n",
    "        data[\"Close_Open_Ratio\"] = data[\"Close\"] / data[\"Open\"]\n",
    "        for lag in lags:\n",
    "            data[f\"Close_Lag_{lag}\"] = data[\"Close\"].shift(lag)\n",
    "            data[f\"Returns_Lag_{lag}\"] = data[\"Returns\"].shift(lag)\n",
    "        logger.info(\"Added price/lag features with lags=%s\", lags)\n",
    "        return data\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Aggregated workflows\n",
    "    # ------------------------------------------------------------------\n",
    "    def prepare_features(self) -> pd.DataFrame:\n",
    "        \"\"\"Compute all indicators and a default next-day return target.\"\"\"\n",
    "        data = self.fetch_stock_data()\n",
    "        self.calculate_moving_averages()\n",
    "        self.calculate_rsi()\n",
    "        self.calculate_macd()\n",
    "        self.calculate_bollinger_bands()\n",
    "        self.calculate_volatility()\n",
    "        self.calculate_volume_indicators()\n",
    "        self.add_price_features()\n",
    "        data = self._require_data()\n",
    "        data[\"Target\"] = data[\"Close\"].shift(-1) / data[\"Close\"] - 1\n",
    "        data.dropna(inplace=True)\n",
    "        logger.info(\"Feature preparation complete. Shape: %s\", data.shape)\n",
    "        return data.copy()\n",
    "\n",
    "    def get_engineered_features(\n",
    "        self,\n",
    "        engineer: Optional[FeatureEngineer] = None,\n",
    "        **engineer_kwargs: Any,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Run the advanced FeatureEngineer on top of the processed dataframe.\"\"\"\n",
    "        if engineer is None:\n",
    "            engineer = FeatureEngineer()\n",
    "        base_df = self.prepare_features()\n",
    "        return engineer.engineer_all_features(base_df, **engineer_kwargs)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Persistence helpers\n",
    "    # ------------------------------------------------------------------\n",
    "    def save_to_csv(self, output_dir: str = \"data\") -> str:\n",
    "        data = self._require_data()\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        path = os.path.join(output_dir, f\"{self.symbol}_stock_data_{timestamp}.csv\")\n",
    "        data.to_csv(path, index=False)\n",
    "        logger.info(\"Data saved to %s\", path)\n",
    "        return path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s:%(message)s\")\n",
    "    collector = StockDataCollector(\"AAPL\", start_date=\"2021-01-01\")\n",
    "    df = collector.prepare_features()\n",
    "    print(\"Prepared dataset shape:\", df.shape)\n",
    "    engineered = collector.get_engineered_features()\n",
    "    print(\"Engineered feature matrix:\", engineered[\"features\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f3b08-1dcc-46f4-9759-93d0b2c7e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./feature_engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddc6cc-487a-4046-8bbc-db94958a29ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
